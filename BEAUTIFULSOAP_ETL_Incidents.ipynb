{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, date\n",
    "import os\n",
    "\n",
    "list_email = ''\n",
    "email_customer = ''\n",
    "\n",
    "# Variaveis\n",
    "db_pbi = ''\n",
    "filepath = ''\n",
    "filepathteste = ''\n",
    "\n",
    "filepath_consultor = ''\n",
    "\n",
    "path_to_read = ''\n",
    "file_to_read_old = ''\n",
    "\n",
    "url_xpto = ''\n",
    "\n",
    "# Historico\n",
    "hist_path = ''\n",
    "arch_name = ''\n",
    "dt_arch = datetime.now().strftime(\"%Y%m%d_%H%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_file_old = os.path.join(path_to_read, file_to_read_old)\n",
    "df_old = pd.read_excel(rf'{read_file_old}')\n",
    "df_old['DF_NAME'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consultor = pd.read_csv(rf'{filepath_consultor}', sep=';', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_xpto(url):\n",
    "    # URL of the API (replace with actual URL if different)\n",
    "\n",
    "    # Fazer a requisição GET\n",
    "    response = requests.get(url, verify=False)\n",
    "\n",
    "    # Verificar o status da requisição\n",
    "    if response.status_code == 200:\n",
    "        # Requisição bem-sucedida\n",
    "        html_content = response.text\n",
    "    else:\n",
    "        # Erro na requisição\n",
    "        print(f\"Erro: {response.status_code}\")\n",
    "        exit()\n",
    "\n",
    "    # Criar um objeto BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "    # Encontrar a tabela\n",
    "    table = soup.find(\"table\")\n",
    "\n",
    "    # Extrair linhas e colunas da tabela\n",
    "    rows = table.find_all(\"tr\")\n",
    "    columns = [th.text for th in rows[0].find_all(\"th\")]\n",
    "\n",
    "    # Extrair dados das células da tabela\n",
    "    data = []\n",
    "    for row in rows[1:]:\n",
    "        data.append([td.text for td in row.find_all(\"td\")])\n",
    "\n",
    "    # Criar o DataFrame\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafael.ferrari\\AppData\\Roaming\\Python\\Python311\\site-packages\\urllib3\\connectionpool.py:1056: InsecureRequestWarning: Unverified HTTPS request is being made to host 'kbi.desk.ms'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_new = extract_xpto(url_xpto)\n",
    "df_new['DF_NAME'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df, dict_df):\n",
    "    df = df.rename(columns=dict_df)\n",
    "    return df\n",
    "\n",
    "\n",
    "def fit_df(df, list_columns):\n",
    "    colcom = list(set(list_columns).intersection(set(df.columns)))\n",
    "    coldif = list(set(list_columns) - set(df.columns))\n",
    "    df = df[colcom]\n",
    "    for each_element in coldif:\n",
    "        df[each_element] = np.NaN\n",
    "    col = colcom + coldif\n",
    "    col = sorted(col)\n",
    "    df = df.loc[:,col]\n",
    "    df = df.drop_duplicates(subset=colcom)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rename_columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m dict_old \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTICKET\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIncident Type\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mINCIDENT_TYPE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCreated Date Time\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCREATED\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStatus\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTATUS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAssigned Team\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGROUP\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      2\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAssigned To\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mASSIGNED_TO\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUBJECT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPriority\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPRIORITY\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClosed Date Time\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCLOSED\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      3\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAssigned To Email\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEMAIL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCategory\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCATEGORY\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstat_Date Time Resolved\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRESOLVED\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDF_NAME\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDF_NAME\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[0;32m      4\u001b[0m dict_new \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNº Chamado\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTICKET\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAssunto\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUBJECT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDescrição\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDESCRIPTION\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNome do Grupo\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGROUP\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      5\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNome Completo do Operador\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mASSIGNED_TO\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData de Criação\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCREATED\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIdade do Chamado - Dias\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAGING\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      6\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIdade da Última Ação do Chamado - Dias\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDAYS_OF_LASTUPDATE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTempo sem Interação\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNO_INTERACTION_TIME\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      7\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmail do Solicitante\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEMAIL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData de Finalização\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCLOSED\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNome do Status\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTATUS\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      8\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProtocolo (Terceiros) da última ação\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLAST_ACTION_PROTOCOL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDF_NAME\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDF_NAME\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCódigo da Prioridade\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPRIORITY\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLAST_ACTION_PROTOCOL\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPROTOCOL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxpto\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxpto\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m---> 11\u001b[0m df_old \u001b[38;5;241m=\u001b[39m \u001b[43mrename_columns\u001b[49m(df_old, dict_old)\n\u001b[0;32m     12\u001b[0m df_new \u001b[38;5;241m=\u001b[39m rename_columns(df_new, dict_new)\n\u001b[0;32m     13\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_old, df_new])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rename_columns' is not defined"
     ]
    }
   ],
   "source": [
    "dict_old = {}\n",
    "dict_new = {}\n",
    "\n",
    "df_old = rename_columns(df_old, dict_old)\n",
    "df_new = rename_columns(df_new, dict_new)\n",
    "df = pd.concat([df_old, df_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafael.ferrari\\AppData\\Local\\Temp\\ipykernel_5192\\369901452.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[each_element] = np.NaN\n",
      "C:\\Users\\rafael.ferrari\\AppData\\Local\\Temp\\ipykernel_5192\\369901452.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[each_element] = np.NaN\n",
      "C:\\Users\\rafael.ferrari\\AppData\\Local\\Temp\\ipykernel_5192\\369901452.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[each_element] = np.NaN\n",
      "C:\\Users\\rafael.ferrari\\AppData\\Local\\Temp\\ipykernel_5192\\369901452.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[each_element] = np.NaN\n",
      "C:\\Users\\rafael.ferrari\\AppData\\Local\\Temp\\ipykernel_5192\\369901452.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[each_element] = np.NaN\n",
      "C:\\Users\\rafael.ferrari\\AppData\\Local\\Temp\\ipykernel_5192\\369901452.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[each_element] = np.NaN\n",
      "C:\\Users\\rafael.ferrari\\AppData\\Local\\Temp\\ipykernel_5192\\369901452.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[each_element] = np.NaN\n",
      "C:\\Users\\rafael.ferrari\\AppData\\Local\\Temp\\ipykernel_5192\\369901452.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[each_element] = np.NaN\n"
     ]
    }
   ],
   "source": [
    "columns=[]\n",
    "\n",
    "\n",
    "def drop_dup_df(df):\n",
    "    df = fit_df(df, columns)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n",
    "\n",
    "df_old = drop_dup_df(df_old)\n",
    "df_new = drop_dup_df(df_new)\n",
    "\n",
    "df_new = df_new[df_new['ASSIGNED_TO'].isin(df_consultor['ASSIGNED_TO'])]\n",
    "\n",
    "#df_old = df_new[df_old['ASSIGNED_TO'].isin(df_consultor['ASSIGNED_TO'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['CLOSED'] = df_new['CLOSED'].replace('00-00-0000', np.NAN) #  0324-001003\n",
    "df_new['CREATED'] = pd.to_datetime(df_new['CREATED'], format='%d-%m-%Y')\n",
    "df_new['CLOSED'] = pd.to_datetime(df_new['CLOSED'], format='%d-%m-%Y')\n",
    "df_tickets = pd.concat([df_new, df_old])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converter datas\n",
    "df_tickets['CLOSED'].replace('00-00-0000', np.NAN, inplace=True)\n",
    "df_tickets['CREATED_DATE_TIME'] = pd.to_datetime(df_tickets['CREATED'], format='mixed')  #, format='%d%m%Y %I:%M %p\n",
    "df_tickets['CLOSED_DATE_TIME'] = pd.to_datetime(df_tickets['CLOSED'], format='mixed')\n",
    "\n",
    "#df_tickets['INCIDENTDURATIONINDAYS'] = df_tickets['INCIDENTDURATIONINDAYS'].apply(lambda x: '{:.2}'.format(x).replace('.', ','))\n",
    "#df_tickets['INCIDENTDURATIONINHOURS'] = df_tickets['INCIDENTDURATIONINHOURS'].apply(lambda x: '{:.2}'.format(x).replace('.', ','))\n",
    "#df_tickets['TOTAL TASK TIME'] = df_tickets['TOTAL TASK TIME'].apply(lambda x: '{:.2}'.format(x).replace('.', ','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the ASSIGNED TEAM rules\n",
    "df_tickets = df_tickets[df_tickets['GROUP'].isin(['KMC GL SAP OPS SD', 'KMC GL SAP OPS LOGISTICS', 'KMC GL SAP OPS MM']) |\n",
    "                        (df_tickets['DF_NAME']=='xpto')]\n",
    "df_tickets['GROUP'] = ['KMC GL SAP OPS SD' if x == 'KMC GL SAP OPS LOGISTICS' else x for x in df_tickets['GROUP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DF_NAME</th>\n",
       "      <th>TICKET</th>\n",
       "      <th>CREATED</th>\n",
       "      <th>CLOSED</th>\n",
       "      <th>CREATED_DATE_TIME</th>\n",
       "      <th>CLOSED_DATE_TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [DF_NAME, TICKET, CREATED, CLOSED, CREATED_DATE_TIME, CLOSED_DATE_TIME]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tickets.loc[df_tickets['CREATED_DATE_TIME']>df_tickets['CLOSED_DATE_TIME'], \\\n",
    "               ['DF_NAME', 'TICKET', 'CREATED', 'CLOSED', 'CREATED_DATE_TIME', 'CLOSED_DATE_TIME']] #.groupby('DF_NAME')['TICKET'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Resolved Status to Closed Status\n",
    "df_tickets['DATE TODAY'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "#df_tickets['DATE TIME CLOSED'] = [dt_resolved if pd.isna(dt_closed) else dt_closed\n",
    "#                                  for dt_resolved, dt_closed in zip(df_tickets['DATE TIME RESOLVED'], df_tickets['DATE TIME CLOSED'])]\n",
    "df_tickets['AGING'] = [(dt_closed - dt_opened).days if not pd.isna(dt_closed) else (datetime.now() - dt_opened).days\n",
    "                        for dt_opened, dt_closed in zip(df_tickets['CREATED_DATE_TIME'], df_tickets['CLOSED_DATE_TIME'])]\n",
    "df_tickets.loc[df_tickets['STATUS'] == 'Resolved', 'STATUS'] = 'Closed'\n",
    "df_tickets.loc[pd.isna(df_tickets['STATUS']), 'STATUS'] = 'In Progress'\n",
    "\n",
    "dict_status = {'Closed':'Closed', 'In Progress':'In Progress', 'Finalizado':'Closed', 'Approval':'In Progress', \n",
    "               'Aguardando Atendimento':'In Progress', 'Aguardando Terceiros':'In Progress', 'Aguardando Cliente':'In Progress',\n",
    "               'Transferência':'In Progress', 'Fluxo de aprovações no Cherwell - USA':'In Progress', 'Cancelado':'Canceled', \n",
    "               'Andamento':'In Progress', 'Acompanhamento':'In Progress', 'Fluxo de aprovações no Cherwell - Business 2024':'In Progress',\n",
    "               'Fluxo de aprovações no Cherwell - Business':'In Progress'}\n",
    "df_tickets['STATUS_AGG'] = df_tickets['STATUS'].replace(dict_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_to_int(df, list_col):\n",
    "    for each_col in list_col:\n",
    "        df.loc[df[each_col]=='', each_col] = 0\n",
    "        df[each_col] = df[each_col].astype('int')\n",
    "    return df\n",
    "    \n",
    "df_tickets = change_to_int(df_tickets, ['PRIORITY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tickets['CHERWELL'] = df_tickets['CHERWELL'].astype('str')\n",
    "\n",
    "def ajusta_inc_sr(df, col_name, col_new_name):\n",
    "    list_inc_sr = []\n",
    "    for each_val in df[col_name]:\n",
    "        if each_val[0:1] == 'S':\n",
    "            list_inc_sr.append('SR')\n",
    "        elif each_val[0:1] == 'I':\n",
    "            list_inc_sr.append('INC')\n",
    "        elif each_val=='':\n",
    "            list_inc_sr.append('INC')\n",
    "        elif each_val[0:1] in ['1', '2', '3', '4', '5', '6', '7', '8', '9', '0']:\n",
    "            list_inc_sr.append('INC')\n",
    "        else:\n",
    "            list_inc_sr.append(np.NaN)\n",
    "    df[col_new_name] = list_inc_sr\n",
    "    return df\n",
    "\n",
    "df_tickets = ajusta_inc_sr(df_tickets, 'CHERWELL', 'INC_SR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tickets.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bulding a Day Calendar with the paremeters already defined before\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "anoini = date.today().year - 3\n",
    "anofim = date.today().year + 1\n",
    "\n",
    "dateiniday = datetime(anoini, 1, 1)\n",
    "datefimday = datetime(anofim, 12, 31)\n",
    "\n",
    "current_year = datetime.today().year\n",
    "current_month = datetime.today().month\n",
    "current_date = datetime.today()\n",
    "l12m = current_date.replace(day=1, hour=0, minute=0, second=0, microsecond=0) + relativedelta(months=-12)\n",
    "l6m = l12m + relativedelta(months= 6)\n",
    "lm_1_ini = current_date.replace(day=1, hour=0, minute=0, second=0, microsecond=0) + relativedelta(months=0)\n",
    "lm_1_fim = current_date.replace(day=1, hour=0, minute=0, second=0, microsecond=0) + relativedelta(months=+1) + relativedelta(days=-1) \n",
    "\n",
    "def convert_str_datetime(data_str):\n",
    "    formato = \"%d/%m/%Y %H:%M:%S\"\n",
    "    data_formatada = datetime.strptime(data_str, formato)\n",
    "    return data_formatada\n",
    "\n",
    "def zero_sec(df, colunas):\n",
    "    for col in pd.DataFrame(df[colunas]).columns:\n",
    "        df[col] = pd.to_datetime(df[col]).dt.floor('min')\n",
    "    return df\n",
    "\n",
    "def calendar():\n",
    "    date_range_minute = pd.date_range(start=dateiniday, end=datefimday, freq='T')\n",
    "\n",
    "    df_calendar_minute = pd.DataFrame({'DATETIME': date_range_minute})\n",
    "\n",
    "    df_calendar_minute['DATETIME'] = pd.to_datetime(df_calendar_minute['DATETIME']) #, format='%Y-%m-%d'\n",
    "    df_calendar_minute['DATE'] = df_calendar_minute['DATETIME'].dt.date\n",
    "\n",
    "    df_calendar_minute['FLAG_CURRENT_MONTH_DATE'] = False\n",
    "    df_calendar_minute['FLAG_CURRENT_YEAR_DATE'] = False\n",
    "    df_calendar_minute['FLAG_L12M_DATE'] = False\n",
    "    df_calendar_minute['FLAG_LM1_DATE'] = False\n",
    "    df_calendar_minute.loc[(df_calendar_minute['DATETIME'].dt.year == current_year) &\n",
    "                    (df_calendar_minute['DATETIME'].dt.month  == current_month),\n",
    "                    'FLAG_CURRENT_MONTH_DATE'] = True\n",
    "    df_calendar_minute.loc[(df_calendar_minute['DATETIME'].dt.year == current_year),\n",
    "                    'FLAG_CURRENT_YEAR_DATE'] = True\n",
    "    df_calendar_minute.loc[(df_calendar_minute['DATETIME'].dt.date >= l12m.date()) & \n",
    "                           (df_calendar_minute['DATETIME'].dt.date <= current_date.date()),\n",
    "                    'FLAG_L12M_DATE'] = True\n",
    "    df_calendar_minute.loc[(df_calendar_minute['DATETIME'].dt.date >= lm_1_ini.date()) & \n",
    "                            (df_calendar_minute['DATETIME'].dt.date <= lm_1_fim.date()), 'FLAG_LM1_DATE'] = True\n",
    "    df_calendar_minute['YEAR_MONTH'] = df_calendar_minute['DATETIME'].dt.to_period('M')\n",
    "    df_calendar_minute['YEAR'] = df_calendar_minute['DATETIME'].dt.year\n",
    "    df_calendar_minute['MONTH'] = df_calendar_minute['DATETIME'].dt.month\n",
    "    df_calendar_minute['DAY'] = df_calendar_minute['DATETIME'].dt.day\n",
    "    df_calendar_minute['MONTH_ABBR'] = df_calendar_minute['DATETIME'].dt.strftime('%b')\n",
    "    df_calendar_minute['TIME'] = df_calendar_minute['DATETIME'].dt.time\n",
    "    df_calendar_minute['WEEKDAY'] = df_calendar_minute['DATETIME'].dt.weekday\n",
    "    df_calendar_minute['WEEK'] = (pd.to_datetime(df_calendar_minute['DATE']).dt.day//7 + 1).astype(int)\n",
    "    df_calendar_minute = df_calendar_minute.sort_values(by='DATETIME', ascending = True)\n",
    "    df_calendar_minute = df_calendar_minute.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    list_holiday = ['2023-01-25', '2023-02-21', '2023-04-07', '2023-04-21', \n",
    "                    '2023-05-01', '2023-06-08', '2023-09-07', '2023-10-12',\n",
    "                    '2023-11-02', '2023-11-15', '2023-12-25', '2022-01-01',\n",
    "                    '2022-03-01', '2022-04-15', '2022-04-21', '2022-06-16',\n",
    "                    '2022-09-07', '2022-10-12', '2022-11-02', '2022-11-15',\n",
    "                    '2022-12-25', '2024-01-01', '2024-03-29', '2024-04-21',\n",
    "                    '2024-05-01', '2024-09-07', '2024-10-12', '2024-10-12',\n",
    "                    '2024-11-02', '2024-11-15', '2024-12-25', '2024-07-09',\n",
    "                    '2024-01-25', '2024-05-30', '2024-11-20', '2024-02-13']\n",
    "\n",
    "    formato = '%Y-%m-%d'\n",
    "    list_holiday = [datetime.strptime(data, formato).date() for data in list_holiday]\n",
    "\n",
    "    # BUSINESS_HOUR\n",
    "    df_calendar_minute['BUSINESS_MIN'] = [1 if (df_calendar_minute['WEEKDAY'].iloc[i] not in (5, 6) and\n",
    "                                    df_calendar_minute['DATE'].iloc[i] not in list_holiday and\n",
    "                                    ((df_calendar_minute['TIME'].iloc[i].hour >= 8 and df_calendar_minute['TIME'].iloc[i].hour < 12) or\n",
    "                                    (df_calendar_minute['TIME'].iloc[i].hour >= 14 and df_calendar_minute['TIME'].iloc[i].hour < 18)))\n",
    "                                    else 0\n",
    "                                    for i in range(len(df_calendar_minute['DATE']))]\n",
    "\n",
    "    last_index = 0\n",
    "    new_index = []\n",
    "\n",
    "    for flag in df_calendar_minute['BUSINESS_MIN']:\n",
    "        if flag == 1:\n",
    "            last_index += 1\n",
    "            new_index.append(last_index)\n",
    "        else:\n",
    "            new_index.append(last_index)\n",
    "\n",
    "    df_calendar_minute = zero_sec(df_calendar_minute, 'DATETIME')\n",
    "            \n",
    "    df_calendar_minute.insert(0, 'INDEX', df_calendar_minute.index)\n",
    "    df_calendar_minute['FLAG_L6M_DATE'] = False\n",
    "    df_calendar_minute.loc[df_calendar_minute['DATE'] >= l6m.date(),'FLAG_L6M_DATE'] = True \n",
    "\n",
    "    df_calendar_day = df_calendar_minute.copy()\n",
    "    df_calendar_day.drop(['DATETIME', 'INDEX', 'TIME', 'BUSINESS_MIN'], axis=1, inplace=True)\n",
    "    df_calendar_day.drop_duplicates(inplace=True)\n",
    "    df_calendar_day.reset_index(inplace=True, drop=True)\n",
    "    df_calendar_day.insert(0, 'INDEX', df_calendar_day.index)\n",
    "\n",
    "    df_calendar_month = pd.DataFrame(df_calendar_day['MONTH_ABBR'].copy())\n",
    "    df_calendar_month.drop_duplicates(inplace=True)\n",
    "    df_calendar_month.reset_index(inplace=True, drop=True)\n",
    "    df_calendar_month.insert(0, 'INDEX', df_calendar_month.index + 1)\n",
    "\n",
    "    df_calendar_year_month = pd.DataFrame(df_calendar_day[['YEAR', 'YEAR_MONTH', 'MONTH', 'MONTH_ABBR', \n",
    "                                                        'FLAG_L12M_DATE', 'FLAG_LM1_DATE']].copy())\n",
    "    #df_calendar_year_month = df_calendar_year_month[df_calendar_year_month['FLAG_L12M_DATE']==True]                                              \n",
    "    df_calendar_year_month.drop_duplicates(inplace=True)\n",
    "    df_calendar_year_month.reset_index(inplace=True, drop=True)\n",
    "    df_calendar_year_month.insert(0, 'INDEX', df_calendar_year_month.index + 1)\n",
    "\n",
    "    df_calendar_minute.to_csv(db_pbi + '\\calendar_minute.csv', sep=';', index=False)\n",
    "    df_calendar_day.to_csv(db_pbi + '\\calendar_day.csv', sep=';', index=False)\n",
    "    df_calendar_month.to_csv(db_pbi + '\\calendar_month.csv', sep=';', index=False)\n",
    "    df_calendar_year_month.to_csv(db_pbi + '\\calendar_year_month.csv', sep=';', index=False)\n",
    "\n",
    "    return [df_calendar_minute, df_calendar_day, df_calendar_month, df_calendar_year_month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_str_datetime(list_df):\n",
    "    for each_df in list_df:\n",
    "        for each_col in each_df.columns:\n",
    "            if each_col == 'DATETIME':\n",
    "                each_df['DATETIME'] = pd.to_datetime(each_df['DATETIME'])\n",
    "            elif each_col == 'DATE':\n",
    "                each_df['DATE'] = pd.to_datetime(each_df['DATE']).dt.date\n",
    "    return list_df\n",
    "\n",
    "def to_check_calendar():\n",
    "    dict_calendar =  {'df_calendar_minute':'calendar_minute.csv', 'df_calendar_day':'calendar_day.csv', \n",
    "                      'df_calendar_month':'calendar_month.csv', 'df_calendar_year_month':'calendar_year_month.csv'}\n",
    "    tof = True\n",
    "    list_return_calendar = []\n",
    "    for key, value in dict_calendar.items():\n",
    "        c = os.path.join(db_pbi, value)\n",
    "        tof = tof * os.path.exists(c)\n",
    "        if tof == True:\n",
    "            key = pd.read_csv(c, sep=';', encoding='latin-1')\n",
    "            list_return_calendar.append(key)\n",
    "        else:\n",
    "            return calendar()\n",
    "\n",
    "    for each_calendar in list_return_calendar:\n",
    "        if 'DATE' in each_calendar.columns:\n",
    "            formato = '%Y-%m-%d'\n",
    "            max_date = datetime.strptime(each_calendar['DATE'].max(), formato).date()\n",
    "            if max_date != datefimday.date():\n",
    "                return calendar()\n",
    "            max_date = 0\n",
    "            formato = ''\n",
    "        elif 'YEAR_MONTH' in each_calendar.columns:\n",
    "            formato = '%Y-%m'\n",
    "            max_date = each_calendar['YEAR_MONTH'].max()\n",
    "            if max_date != current_date.strftime(formato):\n",
    "                return calendar()\n",
    "            max_date = 0\n",
    "            formato = ''\n",
    "        elif 'INDEX' in each_calendar.columns:\n",
    "            #list_month = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "            val_val = set(range(1,13))\n",
    "            index = set(each_calendar['INDEX'])\n",
    "            if val_val != index:\n",
    "                return calendar()\n",
    "    list_return_calendar = change_str_datetime(list_return_calendar)\n",
    "    return calendar()\n",
    "\n",
    "[df_calendar_minute, df_calendar_day, df_calendar_month, df_calendar_year_month] = to_check_calendar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business Hour Index\n",
    "def bsns_hour_index(df):\n",
    "    last_index = 0\n",
    "    new_index = []\n",
    "    for flag in df_calendar_minute['BUSINESS_MIN']:\n",
    "        if flag == 1:\n",
    "            last_index += 1\n",
    "            new_index.append(last_index)\n",
    "        else:\n",
    "            new_index.append(last_index)\n",
    "    return new_index\n",
    "\n",
    "df_calendar_minute['INDEX_BSNS_HOUR'] = bsns_hour_index(df_calendar_minute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tickets['CREATED'] = pd.to_datetime(df_tickets['CREATED'], format='mixed')\n",
    "df_tickets['CLOSED'] = pd.to_datetime(df_tickets['CLOSED'], format='mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create OPENED Table\n",
    "df_opened = df_tickets[(~df_tickets['CREATED'].isna())].copy()\n",
    "df_opened['REFERENCE_AT_DATETIME'] = df_opened['CREATED'] #df_opened['REFERENCE_AT_DATE'] = pd.to_datetime(df_opened['REFERENCE_AT_DATE'])\n",
    "df_opened['STATUS_MONTH'] = 'OPENED'\n",
    "df_opened['COUNT_TICKETS'] = 1\n",
    "df_opened['YTD'] = ['YTD' if datetime.now().year == pd.to_datetime(data).year\n",
    "                    else (pd.to_datetime(data).year - datetime.now().year) \n",
    "                    for data in df_opened['REFERENCE_AT_DATETIME']]\n",
    "\n",
    "# Create Closed Table\n",
    "df_closed = df_tickets[(~df_tickets['CLOSED'].isna())].copy()\n",
    "df_closed['REFERENCE_AT_DATETIME'] = df_closed['CLOSED'] #df_closed['REFERENCE_AT_DATE'] = pd.to_datetime(df_closed['REFERENCE_AT_DATE'])\n",
    "df_closed['STATUS_MONTH'] = 'CLOSED'\n",
    "df_closed['COUNT_TICKETS'] = 1\n",
    "df_closed['YTD'] = ['YTD' if datetime.now().year == pd.to_datetime(data).year\n",
    "                    else (pd.to_datetime(data).year - datetime.now().year) \n",
    "                    for data in df_closed['REFERENCE_AT_DATETIME']]\n",
    "\n",
    "# Create BACKLOG Table\n",
    "df_backlog = df_tickets[((df_tickets['CLOSED'] >= (pd.to_datetime(df_tickets['CREATED_DATE_TIME']) + pd.offsets.MonthBegin(1)).dt.to_period('M').dt.to_timestamp()) &\n",
    "                        ~df_tickets['CLOSED'].isna()) |\n",
    "                        (df_tickets['CLOSED'].isna())].copy()\n",
    "\n",
    "df_backlog['REFERENCE_AT_DATETIME'] = df_backlog['CREATED'] #df_closed['REFERENCE_AT_DATE'] = pd.to_datetime(df_closed['REFERENCE_AT_DATE'])\n",
    "df_backlog['STATUS_MONTH'] = 'BACKLOG'\n",
    "df_backlog['COUNT_TICKETS'] = 1\n",
    "df_backlog['YTD'] = ['YTD' if datetime.now().year == pd.to_datetime(data).year\n",
    "                    else (pd.to_datetime(data).year - datetime.now().year) \n",
    "                    for data in df_backlog['REFERENCE_AT_DATETIME']]\n",
    "# LOOK FOR BACKLOG LINES WITH MORE THAN 1 MONTH OF DIFFERENCE BETWEEN RESOLVED/CLOSED AND OPENED TO INPUT A NEW LINE IN THE GAP MONTH \n",
    "def dup_backlog_line(df):\n",
    "    x = 0\n",
    "    new_series = []\n",
    "    for idx, row in df.iterrows():\n",
    "        x = int(row['datediff'] - 1)\n",
    "        for i in range(x):\n",
    "            row['REFERENCE_AT_DATETIME'] = (pd.to_datetime(row['CREATED']) + pd.DateOffset(months=i+1)).to_period('M').to_timestamp()\n",
    "            #print(str(row['NUMBER']) + ' - ' + str(row['OPENED_AT']) + ' - ' + str(row['REFERENCE_AT_DATETIME']) + ' - ' +  str(row['datediff']) + ' - ' + str(i) + ' - '+ str(x))\n",
    "            new_series.append(row.copy())\n",
    "    return new_series\n",
    "\n",
    "df_backlog_date_dif = df_backlog.copy()\n",
    "df_backlog_date_dif['dateClosedOpened'] = df_backlog_date_dif['CLOSED']\n",
    "df_backlog_date_dif.loc[df_backlog_date_dif['CLOSED'].isna(),'dateClosedOpened'] = datetime.now()\n",
    "df_backlog_date_dif.loc[df_backlog_date_dif['dateClosedOpened'].isna(),'dateClosedOpened'] = df_backlog_date_dif['CLOSED']\n",
    "df_backlog_date_dif['datediff'] = ((pd.to_datetime(df_backlog_date_dif['dateClosedOpened'], format='mixed').dt.year - \n",
    "                                pd.to_datetime(df_backlog_date_dif['CREATED'], format='mixed').dt.year)*12 + \n",
    "                                pd.to_datetime(df_backlog_date_dif['dateClosedOpened'], format='mixed').dt.month - \n",
    "                                pd.to_datetime(df_backlog_date_dif['CREATED'], format='mixed').dt.month)\n",
    "df_backlog_date_dif = df_backlog_date_dif[df_backlog_date_dif['datediff']>1].copy()\n",
    "\n",
    "\n",
    "df_auxiliar = pd.DataFrame(dup_backlog_line(df_backlog_date_dif))\n",
    "df_auxiliar.drop(['dateClosedOpened','datediff'], axis=1, inplace=True)\n",
    "df_backlog  = pd.concat([df_backlog, df_auxiliar], axis=0)\n",
    "\n",
    "# UNION\n",
    "df = pd.concat([df_opened, df_closed, df_backlog], ignore_index=True)\n",
    "\n",
    "# REFERENCE_AT_DATETIME REFERENCE_AT_DATE\n",
    "df['REFERENCE_AT_DATETIME'] = pd.to_datetime(df['REFERENCE_AT_DATETIME'])\n",
    "df['REFERENCE_AT_DATE'] = df['REFERENCE_AT_DATETIME'].dt.date\n",
    "df['REF_Y_M'] = df['REFERENCE_AT_DATETIME'].dt.strftime('%Y-%m')\n",
    "#print(df_gerot_sctask.loc[df_gerot_sctask['NUMBER']==\"SCTASK1535820\", ['NUMBER', 'STATUS_MONTH', 'OPENED_AT', 'CLOSED_AT', 'REFERENCE_AT_DATETIME']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CREATED'] = pd.to_datetime(df['CREATED'], format='mixed').dt.date\n",
    "df['CLOSED'] = pd.to_datetime(df['CLOSED'], format='mixed').dt.date\n",
    "df['RESOLVED'] = pd.to_datetime(df['RESOLVED'], format='mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_aging(df, coluna_aging, coluna_nome):\n",
    "    classificacao = pd.cut(df[coluna_aging], bins=[-1, 15, 30, 45, 60, df[coluna_aging].max()+1], labels=['<15', '<30', '<45', '<60', '>60'])\n",
    "    df[coluna_nome] = classificacao\n",
    "    return df\n",
    "\n",
    "df = class_aging(df, 'AGING', 'CLASS_AGING')\n",
    "\n",
    "df = df.sort_values(by='REFERENCE_AT_DATETIME', ascending=True)\n",
    "\n",
    "df['FLAG_OPENED'] = False\n",
    "df.loc[df['STATUS_AGG'].isin(['In Progress', 'Pending']) &\n",
    "       df['STATUS_MONTH'].isin(['OPENED']), 'FLAG_OPENED'] = True\n",
    "\n",
    "mask = df.loc[(df['STATUS_AGG']=='OPENED') &\n",
    "       (df['STATUS_MONTH']=='BACKLOG'), :].groupby(['TICKET'])['REFERENCE_AT_DATETIME'].idxmax()\n",
    "df.iloc[mask, :].loc[:,'FLAG_OPENED'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DESCRIPTION'] = df['DESCRIPTION'].str.replace('\\n', ' ')\n",
    "df['DESCRIPTION'] = df['DESCRIPTION'].str.replace(';', ',')\n",
    "df['DESCRIPTION'] = df['DESCRIPTION'].str.replace('\\r', ' ')\n",
    "#df['DESCRIPTION'] = \"'\" + df['DESCRIPTION'] + \"'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, df_consultor, left_on='ASSIGNED_TO', right_on='ASSIGNED_TO', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(rf'{filepath}', sep=';', index=False)\n",
    "#df[['STATUS_MONTH', 'TICKET', 'DF_NAME','REF_Y_M','COUNT_TICKETS', 'GROUP']].to_csv(rf'{filepathteste}', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(hist_path + arch_name + str(dt_arch) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Construct the full path to the script (replace with your actual path)\n",
    "script_path = rf\"\"\n",
    "\n",
    "# Prepend the script's directory to the system path (if necessary)\n",
    "if script_path not in sys.path:\n",
    "    sys.path.append(os.path.dirname(script_path))\n",
    "\n",
    "# Now you can import the functions from Funcoes.py\n",
    "from Funcoes import send_email\n",
    "\n",
    "#send_email(list_email, email_customer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
